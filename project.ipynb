{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4988daf4-346a-4a15-b8f8-4802ccdfb87b"
    },
    "tags": [
     "type:NotebookTask",
     "key:1d0b086e6c"
    ]
   },
   "source": [
    "## Searchlights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "@context"
    ]
   },
   "source": [
    "In univariate analyses there is a distinction between whole-brain and ROI-based analyses. When done correctly, whole-brain univariate analyses allow you to identify, in an unbiased and data-driven way, regions of the brain that differ between experimental conditions. Compare this to what we have done with multivariate classification: up to this point we have taken ROIs (e.g., FFA, PPA, even the whole brain) and looked at the pattern of activity across voxels. Using these procedures we have been able to determine whether these voxels collectively contain information about different conditions. However, it has been unclear whether a subset of these voxels have been driving classification accuracy, partly because it is tricky to interpret the resulting weights. In other words, we have been unable to say with certainty *where* in the brain there are representations that distinguish between conditions.\n",
    "\n",
    "A searchlight is a spherical or cubic moving window that allows us to identify and localize such representations. Running a searchlight is computationally intensive because it involves running a separate multivariate analysis for every voxel in the brain. Imagine doing your feature selection, hyper-parameter optimization, and cross-validation 100,000 times or more. Fortunately, brainiak contains a procedure that efficiently carves up brain data into appropriate chunks and distributes them across the computational resources available.\n",
    "             \n",
    "For this script we will use the localizer dataset from Kim et al. (2017). \n",
    "\n",
    "## Goal of this script\n",
    "\n",
    ">Learn how to perform a whole-brain searchlight  \n",
    ">Learn how to replace the kernel used inside the searchlight\n",
    "\n",
    "## Table of contents\n",
    "\n",
    ">1.[Introduction](#introduction)  \n",
    ">2.[Searchlight Workflow](#sl_wf)  \n",
    ">>2.1 [Data Preparation](#data_prep)  \n",
    ">>2.2 [How does the BrainIAK Searchlight work?](#how_sl)  \n",
    ">>2.3 [Executing the Searchlight Workflow](#sl_wf)   \n",
    "\n",
    ">3.[Exercises](#exer)  \n",
    ">>[Exercise 4](#exercise4)  \n",
    ">>[Exercise 5](#exercise5)  \n",
    ">>[Exercise 6](#exercise6)  \n",
    ">>[Exercise 7](#exercise7)  \n",
    ">>[Exercise 8](#exercise8) \n",
    "\n",
    ">4.[Running Searchlights on High Performance Clusters](#submitting_searchlights)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "@instructions"
    ]
   },
   "source": [
    "some instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "@sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Michael note: each task needs sample code, so I put this here for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "tags": [
     "@solution"
    ]
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "type:NotebookTask",
     "key:2d0b086e6c"
    ]
   },
   "source": [
    "## 2. Searchlight Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "@context"
    ]
   },
   "source": [
    "Running a searchlight is computationaly intensive and involves many steps. To help simplify the process,  we recommend runnning small analyses to begin and gradually adding complexity. The following workflow implements this methodology in a sequence of steps. \n",
    ">1. Data Preparation. Read data files, create masks etc. \n",
    ">2. Run a small searchlight: This wll help in getting estimates of how long your full searchlight will run and the resources it need. We start with a toy dataset in this tutorial. \n",
    ">3. Save the data. Map the searchlight results back to brain space.  \n",
    ">4. Run the analysis on a large number of voxels.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "@instructions"
    ]
   },
   "source": [
    "some instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1f7f9d75-833f-410f-8988-58c1618fa753"
    },
    "tags": [
     "@sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from utils import load_data, load_labels, label2TR, shift_timing, reshape_data, blockwise_sampling\n",
    "\n",
    "import time\n",
    "from nilearn import plotting\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from scipy.sparse import random\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "@solution"
    ]
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "type:NotebookTask",
     "key:3d0b086e6c"
    ]
   },
   "source": [
    "## 2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "@context"
    ]
   },
   "source": [
    "Prepare a single participant using a similar pipeline to what we have developed previously. The critical change needed here is the shape of the data: In the past we wanted a trial x voxel matrix, but the input to a searchlight is a 3D volume, hence we need to add a step, as below.\n",
    "\n",
    "<a name=\"exercise1\"></a>\n",
    "**Exercise 1:** Why does the input to a searchlight analysis need to be 3D rather than 2D?  \n",
    "**A:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "@instructions"
    ]
   },
   "source": [
    "some instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "@sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Preset variables\n",
    "dir = '/gpfs/milgram/data/cmhn-s18/datasets/vdc/'\n",
    "num_runs=3\n",
    "TR=1.5\n",
    "hrf_lag = 4.5  # In seconds what is the lag between a stimulus onset and the peak bold response\n",
    "shift_size = int(hrf_lag / TR) # Convert the shift into TRs\n",
    "\n",
    "sub_id = 1\n",
    "\n",
    "# Convert the number into a participant folder name\n",
    "if (sub_id < 10):\n",
    "    sids = '0' + str(sub_id)\n",
    "else:\n",
    "    sids = str(sub_id)   \n",
    "\n",
    "# Specify the subject name\n",
    "sub = 'sub-' + sids\n",
    "\n",
    "# Load subject labels\n",
    "stim_label_allruns = load_labels(dir, sub)\n",
    "\n",
    "# Load the fMRI data\n",
    "epi_mask_data_all, whole_brain_mask = load_data(directory=dir, subject_name=sub, mask_name='', zscore_data=True)\n",
    "\n",
    "# How many events are there on this run\n",
    "_, events = stim_label_allruns.shape\n",
    "events_run = int(events / num_runs)\n",
    "\n",
    "# This can differ per participant\n",
    "print(sub, '= TRs: ', epi_mask_data_all.shape[1], '; Voxels: ', epi_mask_data_all.shape[0])\n",
    "TRs_run = int(epi_mask_data_all.shape[1] / num_runs)\n",
    "\n",
    "# Convert the timing into TR indexes\n",
    "stim_label_TR = label2TR(stim_label_allruns, num_runs, TR, TRs_run)\n",
    "\n",
    "# Shift the data some amount\n",
    "stim_label_TR_shifted = shift_timing(stim_label_TR, shift_size)\n",
    "\n",
    "# Perform the reshaping of the data\n",
    "bold_data, labels = reshape_data(stim_label_TR_shifted, epi_mask_data_all)\n",
    "\n",
    "# Down sample the data to be blockwise rather than trialwise\n",
    "bold_data, labels = blockwise_sampling(bold_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "@solution"
    ]
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape the data so that they are a 3D volume stacked in time (4D array)\n",
    "\n",
    "bold_vol = np.zeros((whole_brain_mask.shape[0], whole_brain_mask.shape[1], whole_brain_mask.shape[2], bold_data.shape[0]))  # Preset the shape of the output\n",
    "coords = np.where(whole_brain_mask)  # Where are the non zero values\n",
    "bold_vol[coords[0], coords[1], coords[2], :] = bold_data.T  # Insert the bold data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Easier Data Processing: Save the formatted Data.\n",
    "Now we save the data you created. We want to do this so that it will be easier to read the data into the searchlight function we will use later. However, be aware that saving many copies of your data is wasteful and unnecessary. In fact, it is the nilearn philosophy to save as little data as possible, ideally only saving your raw data and analysis code -- which are sufficient to replicate the analysis -- along with any outputs needed for visualizing the results. To save data with nibabel we need information about the voxel size and orientation of the brain in the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the nifti parameters (would have been better to get these when we loaded in the data)\n",
    "nii = nib.load(dir + sub + \"/preprocessed/loc/%s_filtered2_d1_firstExampleFunc_r%d.nii\" % (sub, 1))\n",
    "affine_mat = nii.affine  # What is the orientation of the data\n",
    "dimsize = nii.header.get_zooms()  # How big is each dimension of the data (first three are voxel size in mm, last is TR duration in s)\n",
    "\n",
    "output_name = ('%s_input.nii.gz' % (sub))\n",
    "\n",
    "# Save the volume\n",
    "bold_nii = nib.Nifti1Image(bold_vol, affine_mat)\n",
    "hdr = bold_nii.header\n",
    "hdr.set_zooms((dimsize[0], dimsize[1], dimsize[2], dimsize[3]))\n",
    "nib.save(bold_nii, output_name)  # Save\n",
    "\n",
    "# Also save the mask data\n",
    "output_name = ('%s_mask.nii.gz' % (sub))\n",
    "\n",
    "mask_nii = nib.Nifti1Image(whole_brain_mask, affine_mat)\n",
    "hdr = mask_nii.header\n",
    "hdr.set_zooms((dimsize[0], dimsize[1], dimsize[2]))\n",
    "nib.save(mask_nii, output_name)  # Save\n",
    "\n",
    "# Save the label data\n",
    "output_name = ('%s_labels.npy' % (sub))\n",
    "np.save(output_name, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 How does the BrainIAK searchlight work? <a name=\"how_sl\"></a>\n",
    "\n",
    "Below we go through a toy example of a searchlight and then move onto a real example. Think of a searchlight as a processing step in which you pull out a certain size chunk of your data and then perform a kernel operation (specified by a function you write). You can use any kernel on this chunk of data interchangeably. Critically, the searchlight function **does not** specify the analysis you want to perform, all it does is carve up the data.\n",
    "\n",
    "As mentioned before, searchlights are computationally intensive and so we need to be aware of what kind of burden they might impose. In the participant you loaded, we want to perform the operation about 177,000 times (once for each of their brain voxels). If we were to run this serially, even if each operation only took 1 s to complete, the analysis would take 50 hours(!), and only for this one participant. With nested cross-validation or other recursive steps, the full analysis could take months or years (and you'd lose a lot of points on your assignment).\n",
    "\n",
    "Fortunately, the searchlight function in brainiak intelligently parallelizes your data to give you a considerable and scalable speed boost. Parallelization is the idea that when two or more computational tasks can be completed independently (because they don't interact in any way) then it is possible to run these tasks simultaneously on different cores (cores are our unit of serial processing, though there are other parallelizations available within-core, such as threads or even multiple instructions within thread). The nice thing about parallelization is that it is scalable: in general, a job parallelized across 10 cores will run 10 times faster than on one core. For reference, your computer likely has 2, 4, or more cores, so you could speed up processing if you recruited all of these resources (and shut down all other types of background processing). Milgram, the cluster you are running on, has about 1,500 cores, meaning in theory if you could run a job simultaneously across all of these cores then the searchlight we talked about before would be taken down from 50 hours to 2 mins. In practice, there is often some start up cost when calling a function, such as loading the data, which could reduce this benefit a little (maybe to 5 mins).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "So remember, the two main things that determine the speed of a searchlight: the **kernel algorithm** and the **amount of parallelization**.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Searchlight: One small piece at a time.\n",
    "\n",
    "It is important to understand how the Searchlight function in Brainiak works. The searchlight code simply searches for every voxel in the mask that is equal to 1 and then centres a searchlight around this. This means that for every value of 1 in your mask, the searchlight function will apply your kernel function. Hence when writing the kernel you need to keep in mind that the input data that the function receives is not the size of the original data but is instead the size of the searchlight radius. In other words, you might give the searchlight function a brain and mask volume that is 64x64x64 but each kernel operation only runs on a data and mask volume that is 3x3x3 (or whatever your searchlight radius is). As per the logic of searchlights, the centre of each mask in the searchlight will be equal to 1 (otherwise the searchlight wouldn't have selected it).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. The Searchlight Parameters\n",
    "\n",
    "The searchlight function needs the following:  \n",
    "\n",
    "1. **data** = The brain data as a 4D volume.  \n",
    "2. **mask** = A binary mask specifying the \"center\" voxels in the brain around which you want to perform searchlight analyses. A searchlight will be drawn around every voxel = 1; hence, it may include voxels outside of your mask, it is up to you to decide whether then to include them.  \n",
    "3. **bcvar** = An additional variable which can be a list, numpy array, dictionary, etc. you want to use in your searchlight kernel. For instance you might want the condition labels so that you can determine to which condition each 3D volume corresponds. If you don't need to broadcast anything, e.g, when doing RSA, set this to 'None'.  \n",
    "4. **sl_rad** = The size of the searchlight's radius, excluding the center voxel. This means the total volume size of the searchlight, if using a cube, is defined as: ((2 * sl_rad) + 1) ^ 3.  \n",
    "5. **max_blk_edge** = When the searchlight function carves the data up into chunks, it doesn't distribute only a single searchlight's worth of data. Instead, it creates a block of data, with the edge length specified by this variable, which determines the number of searchlights to run within a job.  \n",
    "6. **pool_size** = Maximum number of cores running on a block (typically 1).  \n",
    "\n",
    "<a name=\"exercise2\"></a>\n",
    "**Exercise 2:** Searchlights don't need to be cubes. What other shape(s) does brainiak support and how do you specify this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 Executing the Searchlight Workflow <a id=\"sl_wf\"></a>\n",
    "When getting used to searchlights it is encouraged that you scale up your code gently. This is to prevent the possibility that run a searchlight that takes a very long time to finish only to find there was a small error (this happens a lot!). Instead it is better to write a simple function that runs quickly so you can check your code works properly before scaling up. A simple workflow when testing your searchlight:\n",
    "\n",
    "\n",
    "1. Create a mask of one voxel and run the searchlight interactively (like we are doing now) to check whether the code works.\n",
    "2. Timestamps to extract the execution time  \n",
    "3. Print the number of voxels that are passed to the searchlight function  \n",
    "4. Run the searchlight as a job on the smallest unit of real data you have (a single run or single participant)\n",
    "5. Check the runtime and memory usage of this searchlight (e.g. on slurm: sacct -j $JID --format=jobid,maxvmsize,elapsed).  \n",
    "\n",
    "Taking our own advice, we are going to write a searchlight script below to perform a very, very simple searchlight. In fact we are only going to run this searchlight on one voxel in the brain so that we can see whether our code is working and how long each searchlight would take. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Create Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a mask of only one arbitrary voxel\n",
    "small_mask = np.zeros(whole_brain_mask.shape)\n",
    "small_mask[80, 54, 9] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Set Searchlight Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preset the variables\n",
    "data = bold_vol\n",
    "mask = small_mask\n",
    "bcvar = labels\n",
    "sl_rad = 1\n",
    "max_blk_edge = 5\n",
    "pool_size = 1\n",
    "\n",
    "# We will get back to these commands once we finish running a simple searchlight. \n",
    "#comm = MPI.COMM_WORLD\n",
    "#rank = comm.rank\n",
    "#size = comm.size\n",
    "\n",
    "# Start the clock to time searchlight.\n",
    "begin_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Create Searchlight Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the searchlight object\n",
    "sl = Searchlight(sl_rad=sl_rad,max_blk_edge=max_blk_edge)\n",
    "print(\"Setup searchlight inputs\")\n",
    "print(\"Input data shape: \" + str(data.shape))\n",
    "print(\"Input mask shape: \" + str(mask.shape) + \"\\n\")\n",
    "\n",
    "# Distribute the information to the searchlights (preparing it to run)\n",
    "sl.distribute([data], mask)\n",
    "\n",
    "#Data that is needed for all searchlights is sent to all cores via the sl.broadcast function. In this example, we are sending the labels for classification to all searchlights.\n",
    "sl.broadcast(bcvar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Define the function (a.k.a Kernel) that needs to be computed.\n",
    "\n",
    "This is the function that you want to measure/classify your data with. This could be classifiers, RSA, or any other metric that needs to be computed.\n",
    "\n",
    "**NB.** The work Kernel is used in multiple mathematical/computational contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the kernel, in this case an SVM\n",
    "def calc_svm(data, sl_mask, myrad, bcvar):\n",
    "    \n",
    "    # Pull out the data\n",
    "    data4D = data[0]\n",
    "    labels = bcvar\n",
    "    \n",
    "    bolddata_sl = data4D.reshape(sl_mask.shape[0] * sl_mask.shape[1] * sl_mask.shape[2], data[0].shape[3]).T\n",
    "\n",
    "    # Check if the number of voxels is what you expect.\n",
    "    print(\"Searchlight data shape: \" + str(data[0].shape))\n",
    "    print(\"Searchlight data shape after reshaping: \" + str(bolddata_sl.shape))\n",
    "    print(\"Searchlight mask shape:\" + str(sl_mask.shape) + \"\\n\")\n",
    "    print(\"Searchlight mask (note that the center equals 1):\\n\" + str(sl_mask) + \"\\n\")\n",
    "    \n",
    "    t1 = time.time()\n",
    "    clf = SVC(kernel='linear', C=1)\n",
    "    scores = cross_val_score(clf, bolddata_sl, labels, cv=3)\n",
    "    accuracy = scores.mean()\n",
    "    t2 = time.time()\n",
    "    \n",
    "    print('Kernel duration: ' + str(t2 - t1) + \"\\n\\n\")\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Execute the Searchlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Begin SearchLight\\n\")\n",
    "sl_result = sl.run_searchlight(calc_svm, pool_size=pool_size)\n",
    "print(\"End SearchLight\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print outputs\n",
    "print(\"Summarize searchlight results\")\n",
    "print(\"Number of searchlights run: \" + str(len(sl_result[mask==1])))\n",
    "print(\"Accuracy for each kernel function: \" + str(sl_result[mask==1]))\n",
    "print('Total searchlight duration (including start up time): ' + str(end_time - begin_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Save the results <a name=\"save_results\"></a>\n",
    "\n",
    "As you have seen, the output of the searchlight analysis is a 3D volume with the outputs of your kernel for each voxel it was run on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_name = ('%s_SL_result.nii.gz' % (sub))\n",
    "\n",
    "# Convert the output into what can be used\n",
    "sl_result = sl_result.astype('double')\n",
    "sl_result[np.isnan(sl_result)] = 0  # If there are nans we want this\n",
    "\n",
    "# Save the volume\n",
    "sl_nii = nib.Nifti1Image(sl_result, affine_mat)\n",
    "hdr = sl_nii.header\n",
    "hdr.set_zooms((dimsize[0], dimsize[1], dimsize[2]))\n",
    "nib.save(sl_nii, output_name)  # Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.7 Plotting the data <a name=\"plotting_results\"></a>\n",
    "\n",
    "The nilearn package has multiple plotting options to allow you to view your data within python. This is good for quick visualizations but can be buggy and is not great for exploration. You can also view the data in other packages such as FSL or AFNI. For instance on Milgram, you can run \"module load Apps/FSL/5.0.6; fslview sub-01_SL_result.nii.gz\" to view the results. If you followed the steps above, you likely won't see many bright spots because we only ran the searchlight in a tiny part of the brain. But if you look at the data in fslview and change the coordinates to X=80, Y=54, Z=9 you should see a non-zero value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercises <a name=\"exer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"exercise3\"></a>\n",
    "**Exercise 3:** From the above code make an estimate of how long it would take to run the searchlight on the whole brain, using the same parameters.\n",
    "\n",
    "**A:**\n",
    "\n",
    "\n",
    "<a name=\"exercise4\"></a>\n",
    "**Exercise 4:** What happens if you set sl_rad to 3?\n",
    "\n",
    "**A:**\n",
    "\n",
    "\n",
    "<a name=\"exercise5\"></a>\n",
    "**Exercise 5:** The first input to the Searchlight.distribute is a list. Why would we have multiple entries? What could this be useful for?\n",
    "\n",
    "**A:**\n",
    "\n",
    "\n",
    "For the following exercises copy and paste the above script into the cell below in order to print out all of the required outputs.\n",
    "\n",
    "<a name=\"exercise6\"></a>\n",
    "**Exercise 6:** Modify the small_mask variable to select a 4x4x4 sub-volume of 64 voxels around the voxel in the example above.\n",
    "\n",
    "<a name=\"exercise7\"></a>\n",
    "**Exercise 7:** Modify the calc_svm function to run only if there are at least 14 voxels from the mask in the 27-voxel searchlight centered on each of these 64 voxels, otherwise return -1. This could be useful if you wanted to ignore searchlights near the edge of the brain. \n",
    "\n",
    "<a name=\"exercise8\"></a>\n",
    "**Exercise 8:** Modify the calc_svm function to perform nested cross-validation (use the code you made for the notebook on classification) over different cost parameters of the linear kernel.\n",
    "\n",
    "Before finalizing your answers, **please remove the comments** from within the kernel that print the data shape and mask variable, to keep your output clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submitting searchlights as jobs <a name=\"submitting_searchlights\"></a>\n",
    "\n",
    "Running searchlight analyses through notebooks or interactive sessions isn't tractable for real studies. Although the example above ran quickly and without parallelization, we only performed 64 analyses. Thus, we are now going to write a script to run a searchlight as a \"batch\" job. To learn how to submit jobs, you need to know a bit about slurm, the scheduling system used on Milgram. But don't worry, you have been submitting batch jobs via slurm since the first class -- every time you use ./launch_jupyter.sh, you submit a job.\n",
    "\n",
    "To run a job, a good work flow is to have two scripts: One script that actually does the computation you care about (e.g., a python script like utils.py) and a bash script that sets up the environment and specifies the job parameters. The environment refers to the modules and packages you need to run your job. The job parameters refer to the partition you are going to use (-p), the number of cores (-n), the amount of memory (-m) and required time (-t). To run your job you then call the bash script with something like: 'sbatch script.sh'\n",
    "\n",
    "Lucky for you we have already written the script needed here, called *run_searchlight.sh*. This script is written in the bash command language. Please explore this script to get familar with submitting jobs. You won't need to edit this script for the exercises below, but it will be very useful for future analyses to customize it for your needs (using a text editor like nano or nedit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the bash script for running searchlights\n",
    "!cat run_searchlight.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a job starts, a log file is created that you can look at. You can see any output from your script printed into the log file. To check the status of your job you should use \"squeue -u $USER\". Sometimes your jobs won't run immediately because they are waiting in the queue. Conversely, don't submit too many jobs or your classmates won't be able to run theirs.\n",
    "\n",
    "When you parallelize an analysis across multiple cores, this typically means that each core will run the code independently (though there are ways for cores to communicate directly with each other). This means you will load in all of the data on each core. The searchlight function then notices that there are multiple cores running the same job and assigns different pieces of the data to each core for analysis. The message passing interface (MPI), the parallelizing framework used by brainiak and most high-performance computing applications, keeps track of each core by assigning it a rank, starting at 0. In other words, if you are running an analysis across 2 cores then some of your computations will be run with rank=0 and some with rank=1. After the searchlights have all finished, you need to save the data. MPI makes the results available on all of the cores, but we typically save the results from the rank-0 core.\n",
    "\n",
    "**Self-study:** Check that MPI is handling ranks and blocks as you expected. To do this create a searchlight that outputs the rank (doesn't do anything with the input data). To set this up you probably want to pull out the rank from the global variable MPI ('rank=MPI.COMM_WORLD.rank') on each searchlight and output. You should get different voxels with different rank values in the range of the number of cores you ran and this should be blocky such that each block has the side length of max_blk_edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to write the python script for running searchlights. The file *searchlight.py* has been started with some of the code needed. However, it is missing the meat and potatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the python script for running searchlights\n",
    "!cat searchlight.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"exercise9\"></a>\n",
    "**Exercise 9:** Finish the *searchlight.py* script so that you can run an SVM searchlight (linear, no grid search) like above but over the whole brain. To run the searchlight command as a batch job, enter into your terminal \"sbatch run_searchlight.sh\". **Please make sure no comments are printed out in your kernel**\n",
    "\n",
    "**Self-study:** Another way to check the searchlight function is to give it noise and see whether you get null results. Try rerunning the searchlight but shuffle the label assignment between conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a name=\"exercise10\"></a>\n",
    "**Exercise 10:** Once your analysis has finished (should take ~5 mins), load in the searchlight results and plot them with the imported function [plotting](http://nilearn.github.io/modules/reference.html#module-nilearn.plotting) from nilearn. However, be aware that some of these functions assume the brain is MNI space. If you think this data is not  in MNI space then do not use those plotting tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a name=\"novel\"></a>\n",
    "**Novel contribution:** be creative and make one new discovery by adding an analysis, visualization, or optimization."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
